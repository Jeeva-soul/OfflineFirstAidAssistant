
# ü©∫ Offline First Aid Assistant (GEMMA-2B)

An AI-powered, **fully offline emergency assistant** built using **Google's Gemma-2B-IT** model, designed to guide users in first aid scenarios without internet access. Whether you‚Äôre in a remote location or caught in a natural disaster, this tool ensures help is never out of reach.

---

## üß† Why This Project?

I built this project out of necessity ‚Äî imagining a world where critical information like **"how to stop bleeding"** or **"how to help someone choking"** should never require an internet connection.  
> "In the age of AI, life-saving help shouldn‚Äôt depend on WiFi."

---

## üöÄ What It Does (Current Version)

- ‚úÖ Uses **Gemma-2B-IT** ‚Äî a 2 billion parameter LLM from Google
- ‚úÖ Runs **entirely offline** on CPU (no internet needed)
- ‚úÖ Provides **step-by-step first aid guidance** through natural conversation
- ‚úÖ Minimalist UI using **Gradio**
- ‚úÖ Based on **PyTorch** + Hugging Face Transformers

---

## üß™ What‚Äôs Working Now

- üîπ Downloaded and stored **Gemma-2B-IT** model locally (`.safetensors`, tokenizer, config)
- üîπ Loaded the model using `transformers.AutoModelForCausalLM` and `AutoTokenizer`
- üîπ Built a **Gradio app** to take user input and generate text
- üîπ Tested a prompt:  
  > ‚ÄúWhat should I do if someone has a deep cut and is bleeding?‚Äù  
  ‚úÖ Returned a fully structured, ethical, and helpful response in ~6 minutes (first inference)

---

## üìÅ Folder Structure

```
OfflineFirstAidAssistant/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ gemma-2-2b-it/              # Local model directory with all required files
‚îú‚îÄ‚îÄ app.py                          # Gradio + PyTorch application script
‚îú‚îÄ‚îÄ requirements.txt                # Dependencies (torch, transformers, gradio)
‚îú‚îÄ‚îÄ README.md                       # You're here
```

---

## üîß Tech Stack

| Layer           | Tool / Library           |
|------------------|--------------------------|
| üß† LLM Model      | Google Gemma-2B-IT        |
| ‚öôÔ∏è Framework      | PyTorch                   |
| üìö NLP Toolkit    | Hugging Face Transformers |
| üåê UI             | Gradio                    |
| üíª Mode           | CPU-only, 100% offline    |
| üß± Model Format   | `.safetensors`            |

---

## ‚è±Ô∏è Performance Note

- First inference takes ~6 minutes on a **16 GB RAM** CPU system
- After that, responses are cached and faster
- Memory usage is heavy ‚Äî not suitable for mobile or low-end machines *yet*

---

## üß© Why GEMMA, Not ONNX or Others?

- ‚ùå ONNX not supported for Gemma (error: custom ONNX config required)
- ‚ùå GGUF/Llama.cpp not used due to C++ complexity and mobile limitations
- ‚úÖ Stuck with **PyTorch (CPU)** for full control + transparency
- ‚úÖ Hugging Face ecosystem made it easy to prototype and deploy

---

## üîê Fully Offline Setup

- No external API
- No model downloads at runtime
- Internet can be completely disabled once model is set up

---

## üë£ Steps to Run

### 1. Clone the repo & setup virtual environment
```bash
git clone https://github.com/yourname/OfflineFirstAidAssistant.git
cd OfflineFirstAidAssistant
python -m venv firstaid_env
firstaid_env\Scripts\activate
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Download Gemma-2B-IT manually into:
```
models/gemma-2-2b-it/
‚îú‚îÄ‚îÄ config.json
‚îú‚îÄ‚îÄ tokenizer.json
‚îú‚îÄ‚îÄ tokenizer.model
‚îú‚îÄ‚îÄ tokenizer_config.json
‚îú‚îÄ‚îÄ model-00001-of-00002.safetensors
‚îú‚îÄ‚îÄ model-00002-of-00002.safetensors
```

### 4. Launch the app
```bash
python app.py
```

App will run at: `http://127.0.0.1:7860`

---

## üìå Example Output

**Prompt:**  
> ‚ÄúWhat should I do if someone has a deep cut and is bleeding?‚Äù

**Response:**  
```
I'm an AI and cannot give medical advice. Call emergency services immediately (911 in the US, 999 in the UK).

While waiting for help, here‚Äôs what you can do:
1. Ensure Safety: Check surroundings. Wear gloves if available.
2. Control Bleeding: Apply pressure with a clean cloth.
3. Do Not Remove Objects: If embedded, do not remove sharp objects.
4. Keep Person Calm and Still.
...
```

---

## üìâ Limitations (for now)

| Area              | Status |
|-------------------|--------|
| ONNX Export       | ‚ùå Not supported by Gemma |
| Voice Input       | ‚ùå Not yet implemented |
| Generative Images | ‚ùå Not yet added |
| Mobile Execution  | ‚ùå Not feasible (model too large) |

---

## üîÆ Upcoming Features

- üéôÔ∏è Offline voice input using Vosk or Whisper.cpp
- üñºÔ∏è Step-by-step visual generation (first aid illustrations)
- üîä Text-to-speech playback
- üì¶ `.exe` app bundling (for field/off-grid devices)

---

## üß† Author

**Jeeva Manavalan**  
> Data Scientist | UTA Alumnus | First-generation engineer  
> *"Using local AI to save lives where the cloud can't reach."*

---

## ‚ö†Ô∏è Disclaimer

This is an educational AI tool and **not a substitute for professional medical care**. Always call emergency services in real-life situations.

---
