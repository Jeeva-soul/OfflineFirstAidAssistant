
# ğŸ©º Offline First Aid Assistant (GEMMA-2B)

A fully offline, AI-powered assistant built with Google's **Gemma-2B-IT** model to guide users through emergency **first aid** procedures â€” without requiring internet access.

---

## ğŸš€ Features (Current Version)

- âœ… **Runs Fully Offline** using locally downloaded Gemma-2B-IT model
- âœ… **Natural Language Q&A** on emergency first aid topics
- âœ… **Gradio UI** interface for easy interaction
- âœ… **Ethical Response Control** (includes AI warning for medical limits)
- âœ… Modular Python code (ready for future voice/image integration)

---

## ğŸ§  How It Works

- The project loads the **Gemma-2B-IT** model using Hugging Face's `transformers` library.
- A custom Gradio-based interface receives user queries.
- The model provides step-by-step guidance for emergency situations (e.g., bleeding, choking, CPR).
- All inference is performed **entirely offline**, using your **local CPU** and disk-stored weights.

---

## ğŸ—‚ï¸ Folder Structure

```
OfflineFirstAidAssistant/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ gemma-2-2b-it/                # Locally downloaded model files (.safetensors, tokenizer, config)
â”‚
â”œâ”€â”€ app.py                            # Gradio frontend with Gemma inference backend
â”œâ”€â”€ convert_to_onnx.py (deprecated)   # Initially attempted ONNX conversion (Gemma unsupported)
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ README.md                         # This file
```

---

## ğŸ§ª Sample Response

**Q:** What should I do if someone has a deep cut and is bleeding?

**A:**  
```
I'm an AI and cannot give medical advice. Call emergency services immediately.

However, while waiting for help to arrive, you can follow these steps to help control the bleeding:

1. Ensure Safety:
   - Assess the situation
   - Protect yourself (wear gloves if available)
2. Control the Bleeding:
   - Apply direct pressure with clean cloth or gauze
   - Elevate the injured area if possible
...
```

---

## ğŸ› ï¸ Tech Stack

| Layer        | Technology              |
|--------------|--------------------------|
| ğŸ§  Model      | Google Gemma-2B-IT (local .safetensors) |
| ğŸ” Inference  | PyTorch (CPU-only)       |
| ğŸ“š NLP        | Hugging Face Transformers |
| ğŸ§° UI         | Gradio                   |
| ğŸ’¾ Offline    | Entire project works without internet |

---

## âŒ Known Limitations

- ğŸŒ First response takes ~6 mins (large model + no GPU)
- âš ï¸ ONNX export is not currently supported for Gemma
- ğŸ“± Mobile deployment is not feasible for 2B models due to size
- ğŸ¤ Voice input and ğŸ–¼ï¸ generative visuals are planned but not implemented yet

---

## ğŸ“ˆ Future Plans

- ğŸ—£ï¸ Add offline **voice input** using Vosk
- ğŸ–¼ï¸ Generate step-by-step **illustrations** for procedures
- ğŸ”Š Integrate **text-to-speech** for response playback
- ğŸ“¦ Package app as a portable `.exe` for Windows use

---

## ğŸ“Œ Setup Instructions

### 1. Clone the repository
```bash
git clone https://github.com/yourusername/OfflineFirstAidAssistant.git
cd OfflineFirstAidAssistant
```

### 2. Create and activate environment
```bash
python -m venv firstaid_env
firstaid_env\Scripts\activate  # Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Ensure model is placed locally:
```
models/gemma-2-2b-it/
  â”œâ”€â”€ config.json
  â”œâ”€â”€ tokenizer.json
  â”œâ”€â”€ tokenizer.model
  â”œâ”€â”€ tokenizer_config.json
  â”œâ”€â”€ model-00001-of-00002.safetensors
  â”œâ”€â”€ model-00002-of-00002.safetensors
```

### 5. Run the app
```bash
python app.py
```

Visit `http://127.0.0.1:7860` in your browser.

---

## ğŸ‘¨â€ğŸ’» Author

**Jeeva Manavalan**  
Data Scientist | UTA Alumnus  
*First-generation engineer building tools to save lives with offline AI.*

---

## ğŸ›¡ï¸ Disclaimer

This assistant is for **informational purposes only** and does not replace professional medical advice or emergency services.

---
 
